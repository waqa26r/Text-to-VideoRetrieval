{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: keras in c:\\users\\admin\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (2.12.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\admin\\appdata\\local\\programs\\python\\python39\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\users\\admin\\appdata\\local\\programs\\python\\python39\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\admin\\appdata\\local\\programs\\python\\python39\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\users\\admin\\appdata\\local\\programs\\python\\python39\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\admin\\appdata\\local\\programs\\python\\python39\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\users\\admin\\appdata\\local\\programs\\python\\python39\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\admin\\appdata\\local\\programs\\python\\python39\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\users\\admin\\appdata\\local\\programs\\python\\python39\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\admin\\appdata\\local\\programs\\python\\python39\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\users\\admin\\appdata\\local\\programs\\python\\python39\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\admin\\appdata\\local\\programs\\python\\python39\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\users\\admin\\appdata\\local\\programs\\python\\python39\\lib\\site-packages)\n",
      "WARNING: You are using pip version 21.2.4; however, version 23.1.2 is available.\n",
      "You should consider upgrading via the 'c:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python39\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "pip install keras\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "#import tensorflow.keras.preprocessing.sequence\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "# from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, LSTM, Dense\n",
    "#import keras.preprocessing.sequence.pad_sequences\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'D:\\\\Major23\\\\image_frames1.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m# Load JSON file containing captions\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39;49m(\u001b[39m'\u001b[39;49m\u001b[39mD:\u001b[39;49m\u001b[39m\\\\\u001b[39;49;00m\u001b[39mMajor23\u001b[39;49m\u001b[39m\\\\\u001b[39;49;00m\u001b[39mimage_frames1.json\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mr\u001b[39;49m\u001b[39m'\u001b[39;49m) \u001b[39mas\u001b[39;00m f:\n\u001b[0;32m      3\u001b[0m     captions \u001b[39m=\u001b[39m json\u001b[39m.\u001b[39mload(f)\n\u001b[0;32m      5\u001b[0m \u001b[39m# Extract text and frames from captions\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\IPython\\core\\interactiveshell.py:284\u001b[0m, in \u001b[0;36m_modified_open\u001b[1;34m(file, *args, **kwargs)\u001b[0m\n\u001b[0;32m    277\u001b[0m \u001b[39mif\u001b[39;00m file \u001b[39min\u001b[39;00m {\u001b[39m0\u001b[39m, \u001b[39m1\u001b[39m, \u001b[39m2\u001b[39m}:\n\u001b[0;32m    278\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    279\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mIPython won\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt let you open fd=\u001b[39m\u001b[39m{\u001b[39;00mfile\u001b[39m}\u001b[39;00m\u001b[39m by default \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    280\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    281\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39myou can use builtins\u001b[39m\u001b[39m'\u001b[39m\u001b[39m open.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    282\u001b[0m     )\n\u001b[1;32m--> 284\u001b[0m \u001b[39mreturn\u001b[39;00m io_open(file, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'D:\\\\Major23\\\\image_frames1.json'"
     ]
    }
   ],
   "source": [
    "# Load JSON file containing captions\n",
    "with open('D:\\\\Major23\\\\image_frames1.json', 'r') as f:\n",
    "    captions = json.load(f)\n",
    "\n",
    "# Extract text and frames from captions\n",
    "captions_text = [caption['caption'] for caption in captions]\n",
    "captions_frame_paths = [caption['folder_path'] for caption in captions]\n",
    "\n",
    "# Tokenize captions text\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(captions_text)\n",
    "captions_sequences = tokenizer.texts_to_sequences(captions_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Tokenize captions text\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(captions_text)\n",
    "captions_sequences = tokenizer.texts_to_sequences(captions_text)\n",
    "\n",
    "# Pad sequences to a fixed length\n",
    "max_sequence_length = max(len(seq) for seq in captions_sequences)\n",
    "padded_captions_sequences = pad_sequences(captions_sequences, maxlen=max_sequence_length)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define LSTM model\n",
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=len(tokenizer.word_index)+1, output_dim=128, input_length=max_sequence_length))\n",
    "model.add(LSTM(units=128))\n",
    "model.add(Dense(units=64, activation='relu'))\n",
    "model.add(Dense(units=1, activation='linear'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "2/2 [==============================] - 2s 16ms/step - loss: 2.8540e-04\n",
      "Epoch 2/5\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 6.5941e-05\n",
      "Epoch 3/5\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 7.8428e-05\n",
      "Epoch 4/5\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 9.2517e-06\n",
      "Epoch 5/5\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 3.3127e-05\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1d916c2dc90>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "# Train the model\n",
    "model.fit(padded_captions_sequences, np.zeros(len(captions)), epochs=5, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('textRetr.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a query\n",
    "query = \"a man in a band playing a guitar\"\n",
    "\n",
    "# Tokenize and pad the query\n",
    "query_sequence = tokenizer.texts_to_sequences([query])\n",
    "padded_query_sequence = pad_sequences(query_sequence, maxlen=max_sequence_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 10ms/step\n"
     ]
    }
   ],
   "source": [
    "# Use the model to predict the caption with the highest similarity score\n",
    "similarity_scores = model.predict(padded_captions_sequences)\n",
    "max_index = np.argmax(similarity_scores)\n",
    "\n",
    "start_index = max_index + 1\n",
    "end_index = min(start_index + 20, len(captions))\n",
    "relevant_frame_paths = [frame_path for frames in captions_frame_paths[start_index:end_index] for frame_path in frames]\n",
    "\n",
    "# Construct file paths for relevant frames\n",
    "frame_dir = 'D:\\\\Major23\\\\Filtered'\n",
    "relevant_frame_file_paths = [os.path.join(frame_dir, frame_path) for frame_path in relevant_frame_paths]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Specify the path of the JSON file\n",
    "json_file_path = 'D:\\\\Major23\\\\relevant_frames_t_t_c_copy.json'\n",
    "\n",
    "# Create a dictionary to store the relevant frame file paths\n",
    "data = {'relevant_frames': relevant_frame_file_paths}\n",
    "\n",
    "# Write the data to the JSON file\n",
    "with open(json_file_path, 'w') as json_file:\n",
    "    json.dump(data, json_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['D:\\\\Major23\\\\Filtered\\\\D', 'D:\\\\Major23\\\\Filtered\\\\:', 'D:\\\\', 'D:\\\\Major23\\\\Filtered\\\\M', 'D:\\\\Major23\\\\Filtered\\\\a', 'D:\\\\Major23\\\\Filtered\\\\j', 'D:\\\\Major23\\\\Filtered\\\\o', 'D:\\\\Major23\\\\Filtered\\\\r', 'D:\\\\Major23\\\\Filtered\\\\2', 'D:\\\\Major23\\\\Filtered\\\\3', 'D:\\\\', 'D:\\\\Major23\\\\Filtered\\\\F', 'D:\\\\Major23\\\\Filtered\\\\i', 'D:\\\\Major23\\\\Filtered\\\\l', 'D:\\\\Major23\\\\Filtered\\\\t', 'D:\\\\Major23\\\\Filtered\\\\e', 'D:\\\\Major23\\\\Filtered\\\\r', 'D:\\\\Major23\\\\Filtered\\\\e', 'D:\\\\Major23\\\\Filtered\\\\d', 'D:\\\\Major23\\\\Filtered\\\\D', 'D:\\\\Major23\\\\Filtered\\\\:', 'D:\\\\', 'D:\\\\Major23\\\\Filtered\\\\M', 'D:\\\\Major23\\\\Filtered\\\\a', 'D:\\\\Major23\\\\Filtered\\\\j', 'D:\\\\Major23\\\\Filtered\\\\o', 'D:\\\\Major23\\\\Filtered\\\\r', 'D:\\\\Major23\\\\Filtered\\\\2', 'D:\\\\Major23\\\\Filtered\\\\3', 'D:\\\\', 'D:\\\\Major23\\\\Filtered\\\\F', 'D:\\\\Major23\\\\Filtered\\\\i', 'D:\\\\Major23\\\\Filtered\\\\l', 'D:\\\\Major23\\\\Filtered\\\\t', 'D:\\\\Major23\\\\Filtered\\\\e', 'D:\\\\Major23\\\\Filtered\\\\r', 'D:\\\\Major23\\\\Filtered\\\\e', 'D:\\\\Major23\\\\Filtered\\\\d', 'D:\\\\Major23\\\\Filtered\\\\D', 'D:\\\\Major23\\\\Filtered\\\\:', 'D:\\\\', 'D:\\\\Major23\\\\Filtered\\\\M', 'D:\\\\Major23\\\\Filtered\\\\a', 'D:\\\\Major23\\\\Filtered\\\\j', 'D:\\\\Major23\\\\Filtered\\\\o', 'D:\\\\Major23\\\\Filtered\\\\r', 'D:\\\\Major23\\\\Filtered\\\\2', 'D:\\\\Major23\\\\Filtered\\\\3', 'D:\\\\', 'D:\\\\Major23\\\\Filtered\\\\F', 'D:\\\\Major23\\\\Filtered\\\\i', 'D:\\\\Major23\\\\Filtered\\\\l', 'D:\\\\Major23\\\\Filtered\\\\t', 'D:\\\\Major23\\\\Filtered\\\\e', 'D:\\\\Major23\\\\Filtered\\\\r', 'D:\\\\Major23\\\\Filtered\\\\e', 'D:\\\\Major23\\\\Filtered\\\\d', 'D:\\\\Major23\\\\Filtered\\\\D', 'D:\\\\Major23\\\\Filtered\\\\:', 'D:\\\\', 'D:\\\\Major23\\\\Filtered\\\\M', 'D:\\\\Major23\\\\Filtered\\\\a', 'D:\\\\Major23\\\\Filtered\\\\j', 'D:\\\\Major23\\\\Filtered\\\\o', 'D:\\\\Major23\\\\Filtered\\\\r', 'D:\\\\Major23\\\\Filtered\\\\2', 'D:\\\\Major23\\\\Filtered\\\\3', 'D:\\\\', 'D:\\\\Major23\\\\Filtered\\\\F', 'D:\\\\Major23\\\\Filtered\\\\i', 'D:\\\\Major23\\\\Filtered\\\\l', 'D:\\\\Major23\\\\Filtered\\\\t', 'D:\\\\Major23\\\\Filtered\\\\e', 'D:\\\\Major23\\\\Filtered\\\\r', 'D:\\\\Major23\\\\Filtered\\\\e', 'D:\\\\Major23\\\\Filtered\\\\d', 'D:\\\\Major23\\\\Filtered\\\\D', 'D:\\\\Major23\\\\Filtered\\\\:', 'D:\\\\', 'D:\\\\Major23\\\\Filtered\\\\M', 'D:\\\\Major23\\\\Filtered\\\\a', 'D:\\\\Major23\\\\Filtered\\\\j', 'D:\\\\Major23\\\\Filtered\\\\o', 'D:\\\\Major23\\\\Filtered\\\\r', 'D:\\\\Major23\\\\Filtered\\\\2', 'D:\\\\Major23\\\\Filtered\\\\3', 'D:\\\\', 'D:\\\\Major23\\\\Filtered\\\\F', 'D:\\\\Major23\\\\Filtered\\\\i', 'D:\\\\Major23\\\\Filtered\\\\l', 'D:\\\\Major23\\\\Filtered\\\\t', 'D:\\\\Major23\\\\Filtered\\\\e', 'D:\\\\Major23\\\\Filtered\\\\r', 'D:\\\\Major23\\\\Filtered\\\\e', 'D:\\\\Major23\\\\Filtered\\\\d', 'D:\\\\Major23\\\\Filtered\\\\D', 'D:\\\\Major23\\\\Filtered\\\\:', 'D:\\\\', 'D:\\\\Major23\\\\Filtered\\\\M', 'D:\\\\Major23\\\\Filtered\\\\a', 'D:\\\\Major23\\\\Filtered\\\\j', 'D:\\\\Major23\\\\Filtered\\\\o', 'D:\\\\Major23\\\\Filtered\\\\r', 'D:\\\\Major23\\\\Filtered\\\\2', 'D:\\\\Major23\\\\Filtered\\\\3', 'D:\\\\', 'D:\\\\Major23\\\\Filtered\\\\F', 'D:\\\\Major23\\\\Filtered\\\\i', 'D:\\\\Major23\\\\Filtered\\\\l', 'D:\\\\Major23\\\\Filtered\\\\t', 'D:\\\\Major23\\\\Filtered\\\\e', 'D:\\\\Major23\\\\Filtered\\\\r', 'D:\\\\Major23\\\\Filtered\\\\e', 'D:\\\\Major23\\\\Filtered\\\\d', 'D:\\\\Major23\\\\Filtered\\\\D', 'D:\\\\Major23\\\\Filtered\\\\:', 'D:\\\\', 'D:\\\\Major23\\\\Filtered\\\\M', 'D:\\\\Major23\\\\Filtered\\\\a', 'D:\\\\Major23\\\\Filtered\\\\j', 'D:\\\\Major23\\\\Filtered\\\\o', 'D:\\\\Major23\\\\Filtered\\\\r', 'D:\\\\Major23\\\\Filtered\\\\2', 'D:\\\\Major23\\\\Filtered\\\\3', 'D:\\\\', 'D:\\\\Major23\\\\Filtered\\\\F', 'D:\\\\Major23\\\\Filtered\\\\i', 'D:\\\\Major23\\\\Filtered\\\\l', 'D:\\\\Major23\\\\Filtered\\\\t', 'D:\\\\Major23\\\\Filtered\\\\e', 'D:\\\\Major23\\\\Filtered\\\\r', 'D:\\\\Major23\\\\Filtered\\\\e', 'D:\\\\Major23\\\\Filtered\\\\d', 'D:\\\\Major23\\\\Filtered\\\\D', 'D:\\\\Major23\\\\Filtered\\\\:', 'D:\\\\', 'D:\\\\Major23\\\\Filtered\\\\M', 'D:\\\\Major23\\\\Filtered\\\\a', 'D:\\\\Major23\\\\Filtered\\\\j', 'D:\\\\Major23\\\\Filtered\\\\o', 'D:\\\\Major23\\\\Filtered\\\\r', 'D:\\\\Major23\\\\Filtered\\\\2', 'D:\\\\Major23\\\\Filtered\\\\3', 'D:\\\\', 'D:\\\\Major23\\\\Filtered\\\\F', 'D:\\\\Major23\\\\Filtered\\\\i', 'D:\\\\Major23\\\\Filtered\\\\l', 'D:\\\\Major23\\\\Filtered\\\\t', 'D:\\\\Major23\\\\Filtered\\\\e', 'D:\\\\Major23\\\\Filtered\\\\r', 'D:\\\\Major23\\\\Filtered\\\\e', 'D:\\\\Major23\\\\Filtered\\\\d', 'D:\\\\Major23\\\\Filtered\\\\D', 'D:\\\\Major23\\\\Filtered\\\\:', 'D:\\\\', 'D:\\\\Major23\\\\Filtered\\\\M', 'D:\\\\Major23\\\\Filtered\\\\a', 'D:\\\\Major23\\\\Filtered\\\\j', 'D:\\\\Major23\\\\Filtered\\\\o', 'D:\\\\Major23\\\\Filtered\\\\r', 'D:\\\\Major23\\\\Filtered\\\\2', 'D:\\\\Major23\\\\Filtered\\\\3', 'D:\\\\', 'D:\\\\Major23\\\\Filtered\\\\F', 'D:\\\\Major23\\\\Filtered\\\\i', 'D:\\\\Major23\\\\Filtered\\\\l', 'D:\\\\Major23\\\\Filtered\\\\t', 'D:\\\\Major23\\\\Filtered\\\\e', 'D:\\\\Major23\\\\Filtered\\\\r', 'D:\\\\Major23\\\\Filtered\\\\e', 'D:\\\\Major23\\\\Filtered\\\\d', 'D:\\\\Major23\\\\Filtered\\\\D', 'D:\\\\Major23\\\\Filtered\\\\:', 'D:\\\\', 'D:\\\\Major23\\\\Filtered\\\\M', 'D:\\\\Major23\\\\Filtered\\\\a', 'D:\\\\Major23\\\\Filtered\\\\j', 'D:\\\\Major23\\\\Filtered\\\\o', 'D:\\\\Major23\\\\Filtered\\\\r', 'D:\\\\Major23\\\\Filtered\\\\2', 'D:\\\\Major23\\\\Filtered\\\\3', 'D:\\\\', 'D:\\\\Major23\\\\Filtered\\\\F', 'D:\\\\Major23\\\\Filtered\\\\i', 'D:\\\\Major23\\\\Filtered\\\\l', 'D:\\\\Major23\\\\Filtered\\\\t', 'D:\\\\Major23\\\\Filtered\\\\e', 'D:\\\\Major23\\\\Filtered\\\\r', 'D:\\\\Major23\\\\Filtered\\\\e', 'D:\\\\Major23\\\\Filtered\\\\d', 'D:\\\\Major23\\\\Filtered\\\\D', 'D:\\\\Major23\\\\Filtered\\\\:', 'D:\\\\', 'D:\\\\Major23\\\\Filtered\\\\M', 'D:\\\\Major23\\\\Filtered\\\\a', 'D:\\\\Major23\\\\Filtered\\\\j', 'D:\\\\Major23\\\\Filtered\\\\o', 'D:\\\\Major23\\\\Filtered\\\\r', 'D:\\\\Major23\\\\Filtered\\\\2', 'D:\\\\Major23\\\\Filtered\\\\3', 'D:\\\\', 'D:\\\\Major23\\\\Filtered\\\\F', 'D:\\\\Major23\\\\Filtered\\\\i', 'D:\\\\Major23\\\\Filtered\\\\l', 'D:\\\\Major23\\\\Filtered\\\\t', 'D:\\\\Major23\\\\Filtered\\\\e', 'D:\\\\Major23\\\\Filtered\\\\r', 'D:\\\\Major23\\\\Filtered\\\\e', 'D:\\\\Major23\\\\Filtered\\\\d', 'D:\\\\Major23\\\\Filtered\\\\D', 'D:\\\\Major23\\\\Filtered\\\\:', 'D:\\\\', 'D:\\\\Major23\\\\Filtered\\\\M', 'D:\\\\Major23\\\\Filtered\\\\a', 'D:\\\\Major23\\\\Filtered\\\\j', 'D:\\\\Major23\\\\Filtered\\\\o', 'D:\\\\Major23\\\\Filtered\\\\r', 'D:\\\\Major23\\\\Filtered\\\\2', 'D:\\\\Major23\\\\Filtered\\\\3', 'D:\\\\', 'D:\\\\Major23\\\\Filtered\\\\F', 'D:\\\\Major23\\\\Filtered\\\\i', 'D:\\\\Major23\\\\Filtered\\\\l', 'D:\\\\Major23\\\\Filtered\\\\t', 'D:\\\\Major23\\\\Filtered\\\\e', 'D:\\\\Major23\\\\Filtered\\\\r', 'D:\\\\Major23\\\\Filtered\\\\e', 'D:\\\\Major23\\\\Filtered\\\\d', 'D:\\\\Major23\\\\Filtered\\\\D', 'D:\\\\Major23\\\\Filtered\\\\:', 'D:\\\\', 'D:\\\\Major23\\\\Filtered\\\\M', 'D:\\\\Major23\\\\Filtered\\\\a', 'D:\\\\Major23\\\\Filtered\\\\j', 'D:\\\\Major23\\\\Filtered\\\\o', 'D:\\\\Major23\\\\Filtered\\\\r', 'D:\\\\Major23\\\\Filtered\\\\2', 'D:\\\\Major23\\\\Filtered\\\\3', 'D:\\\\', 'D:\\\\Major23\\\\Filtered\\\\F', 'D:\\\\Major23\\\\Filtered\\\\i', 'D:\\\\Major23\\\\Filtered\\\\l', 'D:\\\\Major23\\\\Filtered\\\\t', 'D:\\\\Major23\\\\Filtered\\\\e', 'D:\\\\Major23\\\\Filtered\\\\r', 'D:\\\\Major23\\\\Filtered\\\\e', 'D:\\\\Major23\\\\Filtered\\\\d', 'D:\\\\Major23\\\\Filtered\\\\D', 'D:\\\\Major23\\\\Filtered\\\\:', 'D:\\\\', 'D:\\\\Major23\\\\Filtered\\\\M', 'D:\\\\Major23\\\\Filtered\\\\a', 'D:\\\\Major23\\\\Filtered\\\\j', 'D:\\\\Major23\\\\Filtered\\\\o', 'D:\\\\Major23\\\\Filtered\\\\r', 'D:\\\\Major23\\\\Filtered\\\\2', 'D:\\\\Major23\\\\Filtered\\\\3', 'D:\\\\', 'D:\\\\Major23\\\\Filtered\\\\F', 'D:\\\\Major23\\\\Filtered\\\\i', 'D:\\\\Major23\\\\Filtered\\\\l', 'D:\\\\Major23\\\\Filtered\\\\t', 'D:\\\\Major23\\\\Filtered\\\\e', 'D:\\\\Major23\\\\Filtered\\\\r', 'D:\\\\Major23\\\\Filtered\\\\e', 'D:\\\\Major23\\\\Filtered\\\\d', 'D:\\\\Major23\\\\Filtered\\\\D', 'D:\\\\Major23\\\\Filtered\\\\:', 'D:\\\\', 'D:\\\\Major23\\\\Filtered\\\\M', 'D:\\\\Major23\\\\Filtered\\\\a', 'D:\\\\Major23\\\\Filtered\\\\j', 'D:\\\\Major23\\\\Filtered\\\\o', 'D:\\\\Major23\\\\Filtered\\\\r', 'D:\\\\Major23\\\\Filtered\\\\2', 'D:\\\\Major23\\\\Filtered\\\\3', 'D:\\\\', 'D:\\\\Major23\\\\Filtered\\\\F', 'D:\\\\Major23\\\\Filtered\\\\i', 'D:\\\\Major23\\\\Filtered\\\\l', 'D:\\\\Major23\\\\Filtered\\\\t', 'D:\\\\Major23\\\\Filtered\\\\e', 'D:\\\\Major23\\\\Filtered\\\\r', 'D:\\\\Major23\\\\Filtered\\\\e', 'D:\\\\Major23\\\\Filtered\\\\d', 'D:\\\\Major23\\\\Filtered\\\\D', 'D:\\\\Major23\\\\Filtered\\\\:', 'D:\\\\', 'D:\\\\Major23\\\\Filtered\\\\M', 'D:\\\\Major23\\\\Filtered\\\\a', 'D:\\\\Major23\\\\Filtered\\\\j', 'D:\\\\Major23\\\\Filtered\\\\o', 'D:\\\\Major23\\\\Filtered\\\\r', 'D:\\\\Major23\\\\Filtered\\\\2', 'D:\\\\Major23\\\\Filtered\\\\3', 'D:\\\\', 'D:\\\\Major23\\\\Filtered\\\\F', 'D:\\\\Major23\\\\Filtered\\\\i', 'D:\\\\Major23\\\\Filtered\\\\l', 'D:\\\\Major23\\\\Filtered\\\\t', 'D:\\\\Major23\\\\Filtered\\\\e', 'D:\\\\Major23\\\\Filtered\\\\r', 'D:\\\\Major23\\\\Filtered\\\\e', 'D:\\\\Major23\\\\Filtered\\\\d', 'D:\\\\Major23\\\\Filtered\\\\D', 'D:\\\\Major23\\\\Filtered\\\\:', 'D:\\\\', 'D:\\\\Major23\\\\Filtered\\\\M', 'D:\\\\Major23\\\\Filtered\\\\a', 'D:\\\\Major23\\\\Filtered\\\\j', 'D:\\\\Major23\\\\Filtered\\\\o', 'D:\\\\Major23\\\\Filtered\\\\r', 'D:\\\\Major23\\\\Filtered\\\\2', 'D:\\\\Major23\\\\Filtered\\\\3', 'D:\\\\', 'D:\\\\Major23\\\\Filtered\\\\F', 'D:\\\\Major23\\\\Filtered\\\\i', 'D:\\\\Major23\\\\Filtered\\\\l', 'D:\\\\Major23\\\\Filtered\\\\t', 'D:\\\\Major23\\\\Filtered\\\\e', 'D:\\\\Major23\\\\Filtered\\\\r', 'D:\\\\Major23\\\\Filtered\\\\e', 'D:\\\\Major23\\\\Filtered\\\\d', 'D:\\\\Major23\\\\Filtered\\\\D', 'D:\\\\Major23\\\\Filtered\\\\:', 'D:\\\\', 'D:\\\\Major23\\\\Filtered\\\\M', 'D:\\\\Major23\\\\Filtered\\\\a', 'D:\\\\Major23\\\\Filtered\\\\j', 'D:\\\\Major23\\\\Filtered\\\\o', 'D:\\\\Major23\\\\Filtered\\\\r', 'D:\\\\Major23\\\\Filtered\\\\2', 'D:\\\\Major23\\\\Filtered\\\\3', 'D:\\\\', 'D:\\\\Major23\\\\Filtered\\\\F', 'D:\\\\Major23\\\\Filtered\\\\i', 'D:\\\\Major23\\\\Filtered\\\\l', 'D:\\\\Major23\\\\Filtered\\\\t', 'D:\\\\Major23\\\\Filtered\\\\e', 'D:\\\\Major23\\\\Filtered\\\\r', 'D:\\\\Major23\\\\Filtered\\\\e', 'D:\\\\Major23\\\\Filtered\\\\d', 'D:\\\\Major23\\\\Filtered\\\\D', 'D:\\\\Major23\\\\Filtered\\\\:', 'D:\\\\', 'D:\\\\Major23\\\\Filtered\\\\M', 'D:\\\\Major23\\\\Filtered\\\\a', 'D:\\\\Major23\\\\Filtered\\\\j', 'D:\\\\Major23\\\\Filtered\\\\o', 'D:\\\\Major23\\\\Filtered\\\\r', 'D:\\\\Major23\\\\Filtered\\\\2', 'D:\\\\Major23\\\\Filtered\\\\3', 'D:\\\\', 'D:\\\\Major23\\\\Filtered\\\\F', 'D:\\\\Major23\\\\Filtered\\\\i', 'D:\\\\Major23\\\\Filtered\\\\l', 'D:\\\\Major23\\\\Filtered\\\\t', 'D:\\\\Major23\\\\Filtered\\\\e', 'D:\\\\Major23\\\\Filtered\\\\r', 'D:\\\\Major23\\\\Filtered\\\\e', 'D:\\\\Major23\\\\Filtered\\\\d', 'D:\\\\Major23\\\\Filtered\\\\D', 'D:\\\\Major23\\\\Filtered\\\\:', 'D:\\\\', 'D:\\\\Major23\\\\Filtered\\\\M', 'D:\\\\Major23\\\\Filtered\\\\a', 'D:\\\\Major23\\\\Filtered\\\\j', 'D:\\\\Major23\\\\Filtered\\\\o', 'D:\\\\Major23\\\\Filtered\\\\r', 'D:\\\\Major23\\\\Filtered\\\\2', 'D:\\\\Major23\\\\Filtered\\\\3', 'D:\\\\', 'D:\\\\Major23\\\\Filtered\\\\F', 'D:\\\\Major23\\\\Filtered\\\\i', 'D:\\\\Major23\\\\Filtered\\\\l', 'D:\\\\Major23\\\\Filtered\\\\t', 'D:\\\\Major23\\\\Filtered\\\\e', 'D:\\\\Major23\\\\Filtered\\\\r', 'D:\\\\Major23\\\\Filtered\\\\e', 'D:\\\\Major23\\\\Filtered\\\\d']\n"
     ]
    }
   ],
   "source": [
    "print(relevant_frame_file_paths)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: File D:\\Major23\\Filtered\\D not found.\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "[Errno 22] Invalid argument: 'D:\\\\Major23\\\\Filtered\\\\:'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[20], line 20\u001b[0m\n\u001b[0;32m     17\u001b[0m     output_file_path \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(result, filename)\n\u001b[0;32m     19\u001b[0m     \u001b[39m# Copy the frame to the output folder\u001b[39;00m\n\u001b[1;32m---> 20\u001b[0m     shutil\u001b[39m.\u001b[39;49mcopy2(frame_path, output_file_path)\n\u001b[0;32m     21\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mSuccessfully copied \u001b[39m\u001b[39m{\u001b[39;00mframe_path\u001b[39m}\u001b[39;00m\u001b[39m to \u001b[39m\u001b[39m{\u001b[39;00moutput_file_path\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     22\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mFileNotFoundError\u001b[39;00m:\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_3.11.1008.0_x64__qbz5n2kfra8p0\\Lib\\shutil.py:436\u001b[0m, in \u001b[0;36mcopy2\u001b[1;34m(src, dst, follow_symlinks)\u001b[0m\n\u001b[0;32m    434\u001b[0m \u001b[39mif\u001b[39;00m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39misdir(dst):\n\u001b[0;32m    435\u001b[0m     dst \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(dst, os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mbasename(src))\n\u001b[1;32m--> 436\u001b[0m copyfile(src, dst, follow_symlinks\u001b[39m=\u001b[39;49mfollow_symlinks)\n\u001b[0;32m    437\u001b[0m copystat(src, dst, follow_symlinks\u001b[39m=\u001b[39mfollow_symlinks)\n\u001b[0;32m    438\u001b[0m \u001b[39mreturn\u001b[39;00m dst\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_3.11.1008.0_x64__qbz5n2kfra8p0\\Lib\\shutil.py:256\u001b[0m, in \u001b[0;36mcopyfile\u001b[1;34m(src, dst, follow_symlinks)\u001b[0m\n\u001b[0;32m    254\u001b[0m     os\u001b[39m.\u001b[39msymlink(os\u001b[39m.\u001b[39mreadlink(src), dst)\n\u001b[0;32m    255\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 256\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39m(src, \u001b[39m'\u001b[39m\u001b[39mrb\u001b[39m\u001b[39m'\u001b[39m) \u001b[39mas\u001b[39;00m fsrc:\n\u001b[0;32m    257\u001b[0m         \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    258\u001b[0m             \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39m(dst, \u001b[39m'\u001b[39m\u001b[39mwb\u001b[39m\u001b[39m'\u001b[39m) \u001b[39mas\u001b[39;00m fdst:\n\u001b[0;32m    259\u001b[0m                 \u001b[39m# macOS\u001b[39;00m\n",
      "\u001b[1;31mOSError\u001b[0m: [Errno 22] Invalid argument: 'D:\\\\Major23\\\\Filtered\\\\:'"
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "\n",
    "# Specify the output folder path\n",
    "result = 'D:\\\\Major23\\\\RelevantFrames_copy'\n",
    "\n",
    "# Create the output folder if it doesn't exist\n",
    "if not os.path.exists(result):\n",
    "    os.makedirs(result)\n",
    "\n",
    "# Copy the relevant frames to the output folder\n",
    "for frame_path in relevant_frame_file_paths:\n",
    "    try:\n",
    "        # Extract the filename from the frame path\n",
    "        filename = os.path.basename(frame_path)\n",
    "\n",
    "        # Construct the output file path\n",
    "        output_file_path = os.path.join(result, filename)\n",
    "\n",
    "        # Copy the frame to the output folder\n",
    "        shutil.copy2(frame_path, output_file_path)\n",
    "        print(f\"Successfully copied {frame_path} to {output_file_path}\")\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: File {frame_path} not found.\")\n",
    "\n",
    "print(\"All relevant frames have been copied to the output folder.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "string indices must be integers, not 'str'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[28], line 19\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[39mfor\u001b[39;00m frame_info \u001b[39min\u001b[39;00m frame_data:\n\u001b[0;32m     17\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     18\u001b[0m         \u001b[39m# Get the frame path from the JSON data\u001b[39;00m\n\u001b[1;32m---> 19\u001b[0m         frame_path \u001b[39m=\u001b[39m frame_info[\u001b[39m'\u001b[39;49m\u001b[39mframe_path\u001b[39;49m\u001b[39m'\u001b[39;49m]\n\u001b[0;32m     21\u001b[0m         \u001b[39m# Read the frame from the file\u001b[39;00m\n\u001b[0;32m     22\u001b[0m         frame \u001b[39m=\u001b[39m cv2\u001b[39m.\u001b[39mimread(frame_path)\n",
      "\u001b[1;31mTypeError\u001b[0m: string indices must be integers, not 'str'"
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "import cv2\n",
    "\n",
    "# Specify the output folder path\n",
    "output_folder_path = 'D:\\\\Major23\\\\RelevantFrames_copy'\n",
    "\n",
    "# Create the output folder if it doesn't exist\n",
    "if not os.path.exists(output_folder_path):\n",
    "    os.makedirs(output_folder_path)\n",
    "\n",
    "# Read the frames from the output.json file\n",
    "with open('relevant_frames_t_t_c_copy.json', 'r') as json_file:\n",
    "    frame_data = json.load(json_file)\n",
    "\n",
    "# Copy the relevant frames to the output folder\n",
    "for frame_info in frame_data:\n",
    "    try:\n",
    "        # Get the frame path from the JSON data\n",
    "        frame_path = frame_info['frame_path']\n",
    "\n",
    "        # Read the frame from the file\n",
    "        frame = cv2.imread(frame_path)\n",
    "\n",
    "        # Check if the frame is successfully read\n",
    "        if frame is None:\n",
    "            print(f\"Error: Failed to read frame from {frame_path}\")\n",
    "            continue\n",
    "\n",
    "        # Extract the filename from the frame path\n",
    "        filename = os.path.basename(frame_path)\n",
    "\n",
    "        # Construct the output file path\n",
    "        output_file_path = os.path.join(output_folder_path, filename)\n",
    "\n",
    "        # Copy the frame to the output folder\n",
    "        cv2.imwrite(output_file_path, frame)\n",
    "        print(f\"Successfully copied {frame_path} to {output_file_path}\")\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: File {frame_path} not found.\")\n",
    "\n",
    "print(\"All relevant frames have been copied to the output folder.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[23], line 57\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(relevant_frame_file_paths) \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m     56\u001b[0m     frame \u001b[39m=\u001b[39m cv2\u001b[39m.\u001b[39mimread(relevant_frame_file_paths[\u001b[39m0\u001b[39m])\n\u001b[1;32m---> 57\u001b[0m     height, width, channels \u001b[39m=\u001b[39m frame\u001b[39m.\u001b[39;49mshape\n\u001b[0;32m     58\u001b[0m     size \u001b[39m=\u001b[39m (width, height)\n\u001b[0;32m     60\u001b[0m     \u001b[39m# Convert the frames to a video\u001b[39;00m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "def convert_frames_to_video(input_list, output_file_name, fps, size):\n",
    "    # Define the output video writer object \n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v') # Define the codec (FourCC code)\n",
    "    out = cv2.VideoWriter(output_file_name, fourcc, fps, size)\n",
    "    \n",
    "    # Loop through the input frames and add them to the output video\n",
    "    for i, img_name in enumerate(input_list):\n",
    "        img_path = os.path.join(input_frame_path, img_name)\n",
    "        img = cv2.imread(img_path)\n",
    "        \n",
    "        if img is None: # Skip if the image cannot be read\n",
    "            print(img_name + ' does not exist')\n",
    "            continue\n",
    "        \n",
    "        out.write(img) # Write out frame to video\n",
    "        \n",
    "        # Show the image in a window (optional)\n",
    "        cv2.imshow('img', img)\n",
    "        cv2.waitKey(1)\n",
    "    \n",
    "    # Release everything if job is finished\n",
    "    out.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    \n",
    "    print(\"The output video {} is saved.\".format(output_file_name))\n",
    "\n",
    "if __name__=='__main__':\n",
    "    # Set up paths and directories\n",
    "    data_dir = 'D:\\\\Major23'\n",
    "    data_subdir = 'Filtered'\n",
    "    input_frame_path = os.path.join(data_dir, data_subdir)\n",
    "    \n",
    "    output_vid_dir = 'D:\\\\Major23\\\\video'\n",
    "    if not os.path.exists(output_vid_dir):\n",
    "        os.mkdir(output_vid_dir)\n",
    "    \n",
    "    # Set up parameters for output video\n",
    "    fps = 5\n",
    "    output_file_name = os.path.join(output_vid_dir, 'o/p_video1.mp4')\n",
    "    \n",
    "    # Load the relevant frame file paths from JSON\n",
    "    json_file_path = 'D:\\\\Major23\\\\relevant_frames_t_t_c_copy.json'\n",
    "    if os.path.exists(json_file_path):\n",
    "        with open(json_file_path) as json_file:\n",
    "            json_data = json.load(json_file)\n",
    "        \n",
    "        relevant_frame_file_paths = json_data.get('relevant_frames', [])\n",
    "    else:\n",
    "        print(\"JSON file does not exist.\")\n",
    "        relevant_frame_file_paths = []\n",
    "    \n",
    "    # Get the size of the frames from the first image\n",
    "    if len(relevant_frame_file_paths) > 0:\n",
    "        frame = cv2.imread(relevant_frame_file_paths[0])\n",
    "        height, width, channels = frame.shape\n",
    "        size = (width, height)\n",
    "        \n",
    "        # Convert the frames to a video\n",
    "        convert_frames_to_video(relevant_frame_file_paths, output_file_name, fps, size)\n",
    "    else:\n",
    "        print(\"No relevant frame file paths found.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The output video D:\\Major23\\video\\outputvideo21.mp4 is saved.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import os\n",
    "\n",
    "def convert_frames_to_video(input_list, output_file_name, fps, size):\n",
    "    # Define the output video writer object \n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v') # Define the codec (FourCC code)\n",
    "    out = cv2.VideoWriter(output_file_name, fourcc, fps, size)\n",
    "    \n",
    "    # Loop through the input frames and add them to the output video\n",
    "    for i, img_name in enumerate(input_list):\n",
    "        img_path = os.path.join(input_frame_path, img_name)\n",
    "        img = cv2.imread(img_path)\n",
    "        \n",
    "        if img is None: # Skip if the image cannot be read\n",
    "            print(img_name + ' does not exist')\n",
    "            continue\n",
    "        \n",
    "        out.write(img) # Write out frame to video\n",
    "        \n",
    "        # Show the image in a window (optional)\n",
    "        cv2.imshow('img', img)\n",
    "        cv2.waitKey(1)\n",
    "    \n",
    "    # Release everything if job is finished\n",
    "    out.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    \n",
    "    print(\"The output video {} is saved.\".format(output_file_name))\n",
    "\n",
    "if __name__=='__main__':\n",
    "    # Set up paths and directories\n",
    "    data_dir = 'D:\\\\Major23'\n",
    "    data_subdir = 'Filtered'\n",
    "    input_frame_path = os.path.join(data_dir, data_subdir)\n",
    "    \n",
    "    output_vid_dir = 'D:\\\\Major23\\\\video'\n",
    "    if not os.path.exists(output_vid_dir):\n",
    "        os.mkdir(output_vid_dir)\n",
    "    \n",
    "    # Set up parameters for output video\n",
    "    fps = 5\n",
    "    output_file_name = os.path.join(output_vid_dir, 'outputvideo1.mp4')\n",
    "    \n",
    "    # Get the size of the frames from the first image\n",
    "    frame = cv2.imread(os.path.join(input_frame_path, os.listdir(input_frame_path)[0]))\n",
    "    height, width, channels = frame.shape\n",
    "    size = (width, height)\n",
    "    \n",
    "    # Convert the frames to a video\n",
    "    img_list = sorted(os.listdir(input_frame_path)) # Sort the image names\n",
    "    convert_frames_to_video(img_list, output_file_name, fps, size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "\n",
    "# Set up video writer\n",
    "video_dir = 'D:\\\\Major23\\\\video'\n",
    "if not os.path.exists(video_dir):\n",
    "    os.makedirs(video_dir)\n",
    "video_path = os.path.join(video_dir, 'output_video.mp4')\n",
    "frame_width = 640  # Adjust to desired frame size\n",
    "frame_height = 480\n",
    "fps = 30\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "video_writer = cv2.VideoWriter(video_path, fourcc, fps, (frame_width, frame_height))\n",
    "\n",
    "# Iterate over frames and add to video\n",
    "frame_dir = 'D:\\\\Major23\\\\Filtered'  # Specify the directory where the frames are located\n",
    "for frame_path in relevant_frame_file_paths:\n",
    "    # Load frame\n",
    "    frame = cv2.imread(frame_path)\n",
    "\n",
    "    # Check if frame is valid\n",
    "    if frame is not None:\n",
    "        # Resize frame to desired dimensions\n",
    "        frame = cv2.resize(frame, (frame_width, frame_height))\n",
    "\n",
    "        # Write frame to video\n",
    "        video_writer.write(frame)\n",
    "\n",
    "# Release video writer\n",
    "video_writer.release()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
